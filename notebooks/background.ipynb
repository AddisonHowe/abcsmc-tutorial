{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "## Bayesian inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from abcsmc.kernels import UniformKernel, GaussianKernel, MVNKernel, LOCMKernel\n",
    "from abcsmc.abcsmc import abcsmc\n",
    "from abcsmc.plotting import plot_results\n",
    "from abcsmc.models import GaussianModel, RingModel\n",
    "from abcsmc.priors import UniformPrior, GaussianPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1 = GaussianModel(1, 1)\n",
    "data = box1.generate_data(1000)\n",
    "data_mu = np.mean(data)\n",
    "data_var = np.var(data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.hist(\n",
    "    data, bins=20, density=True, \n",
    ")\n",
    "ax.text(0.75, 0.75, f\"$\\mu={data_mu:.6g}$\\n$\\sigma^2={data_var:.6g}$\",\n",
    "         transform = ax.transAxes, fontsize=10)\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(\"Observed data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mu = UniformPrior(-4, 4)\n",
    "prior_var = UniformPrior(0.00, 5)\n",
    "\n",
    "def compute_loglikelihood(x, theta):\n",
    "    mus = theta[:,0]\n",
    "    sigmas = np.sqrt(theta[:,1])\n",
    "    ll = -0.5 * ((x[:,None] - mus)/sigmas)**2 - np.log(sigmas) - 0.5*np.log(2*np.pi)\n",
    "    return np.sum(ll, axis=0)\n",
    "\n",
    "def compute_logprior(theta):\n",
    "    mus = theta[:,0]\n",
    "    vars = theta[:,1]\n",
    "    return np.log(prior_mu.pdf(mus)) + np.log(prior_var.pdf(vars))\n",
    "\n",
    "def compute_logposterior(theta, x):\n",
    "    return compute_loglikelihood(x, theta) + compute_logprior(theta)\n",
    "\n",
    "nparticles = 20000\n",
    "params = np.zeros([nparticles, 2])\n",
    "params[:,0] = prior_mu.rvs(nparticles)\n",
    "params[:,1] = prior_var.rvs(nparticles)\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(8,4))\n",
    "\n",
    "xs = np.linspace(-10, 10, 1000)\n",
    "ys = prior_mu.pdf(xs)\n",
    "ax1.plot(xs, ys)\n",
    "\n",
    "xs = np.linspace(-10, 10, 1000)\n",
    "ys = prior_var.pdf(xs)\n",
    "ax2.plot(xs, ys)\n",
    "\n",
    "ax1.set_xlabel('$\\mu$')\n",
    "ax1.set_ylabel('PDF')\n",
    "ax2.set_xlabel('$\\sigma^2$')\n",
    "ax2.set_ylabel('PDF')\n",
    "\n",
    "fig.suptitle('Priors')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = compute_loglikelihood(data, params)\n",
    "lp = compute_logprior(params)\n",
    "\n",
    "logposterior = ll + lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxidx = np.argmax(logposterior)\n",
    "mu_amax, var_amax = params[maxidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridn = 400\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "xs = np.linspace(-5, 5, gridn)\n",
    "ys = np.linspace(0.0, 6, gridn)\n",
    "Xs, Ys = np.meshgrid(xs, ys)\n",
    "xys = np.array([Xs, Ys]).reshape([2, -1]).T\n",
    "zs = compute_logposterior(xys, data).reshape([gridn, gridn])\n",
    "zs[~np.isfinite(zs)] = -np.nan\n",
    "\n",
    "sc = ax.pcolor(xs, ys, -zs, cmap='jet_r',\n",
    "    norm=LogNorm(vmin=-np.nanmax(zs), vmax=-np.nanmin(zs))\n",
    ")\n",
    "\n",
    "amax = xys[np.nanargmax(zs)]\n",
    "ax.plot(\n",
    "    amax[0], amax[1], \n",
    "    'ok', markersize=5,\n",
    "    label= f\"Max:\\n$\\mu={amax[0]:.6g}$\\n$\\sigma^2={amax[1]:.6g}$\"\n",
    ")\n",
    "\n",
    "fig.colorbar(sc, ax=ax, label='$-\\log$[posterior]')\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel(\"$\\mu$\")\n",
    "ax.set_ylabel(\"$\\sigma^2$\")\n",
    "ax.set_title(f\"Posterior: $P(\\mu,\\sigma^2|D)$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "sc = ax.scatter(\n",
    "    params[:,0], params[:,1], \n",
    "    alpha=0.5,\n",
    "    c=-logposterior, cmap='jet_r', s=2,\n",
    "    norm=LogNorm(vmin=-logposterior.max(), vmax=-logposterior.min())\n",
    ")\n",
    "ax.plot(\n",
    "    params[maxidx, 0], params[maxidx, 1], \n",
    "    'ok', markersize=5,\n",
    "    label= f\"Max:\\n$\\mu={mu_amax:.4g}$\\n$\\sigma^2={var_amax:.4g}$\"\n",
    ")\n",
    "ax.set_xlabel(\"$\\mu$\")\n",
    "ax.set_ylabel(\"$\\sigma^2$\")\n",
    "ax.legend(loc='upper right')\n",
    "# fig.colorbar(sc, ax=ax, label='$-\\log\\{p(x|\\\\theta)p(\\\\theta)\\}$');\n",
    "fig.colorbar(sc, ax=ax, label='$-\\log$[posterior]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mu = 1\n",
    "true_var = 1\n",
    "data = GaussianModel(true_mu, true_var).generate_data(1000)\n",
    "data_mu = np.mean(data)\n",
    "data_var = np.var(data)\n",
    "\n",
    "prior_mu = UniformPrior(-4, 4)\n",
    "prior_var = UniformPrior(0.0, 5)\n",
    "prior_list = [prior_mu, prior_var]\n",
    "\n",
    "pname1=\"$\\mu$\"\n",
    "pname2=\"$\\sigma^2$\"\n",
    "\n",
    "def f_sim(particle, n=100):\n",
    "    return GaussianModel(particle[0], particle[1]).generate_data(n)\n",
    "\n",
    "def f_dist(x):\n",
    "    mu_err = np.abs(np.mean(x) - data_mu) / data_mu\n",
    "    var_err = np.abs(np.var(x) - data_var) / data_var\n",
    "    return mu_err + var_err\n",
    "\n",
    "particles, weights, results_dict = abcsmc(\n",
    "    nparticles=1000, \n",
    "    nparams=2, \n",
    "    prior_list=prior_list, \n",
    "    niters=5, \n",
    "    sim_func=f_sim,\n",
    "    dist_func=f_dist, \n",
    "    eps0=5, \n",
    "    eps_percentile=0.15, \n",
    "    min_eps=0, \n",
    "    kernel_method='locm'\n",
    ")\n",
    "\n",
    "particle_history = results_dict['particle_history']\n",
    "weight_history = results_dict['weight_history']\n",
    "score_history = results_dict['score_history']\n",
    "acceptance_rates = results_dict['acceptance_rates']\n",
    "epsilon_history = results_dict['epsilon_history']\n",
    "niters = results_dict['niters']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(\n",
    "    particle_history, weight_history, score_history, acceptance_rates,\n",
    "    epsilon_history, prior_list,\n",
    "    pname1=pname1, pname2=pname2,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ring Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_theta1 = 10\n",
    "true_theta2 = 8\n",
    "var_const = 0.5\n",
    "data = RingModel(true_theta1, true_theta2, var_const).generate_data(1000)\n",
    "\n",
    "data_mu = np.mean(data)\n",
    "data_var = np.var(data)\n",
    "\n",
    "prior_theta1 = st.uniform(-50, 100)\n",
    "prior_theta2 = st.uniform(-50, 100)\n",
    "prior_list = [prior_theta1, prior_theta2]\n",
    "\n",
    "def f_sim(particle, n=100):\n",
    "    return RingModel(particle[0], particle[1], var_const).generate_data(n)\n",
    "\n",
    "def f_dist(x):\n",
    "    mu_err = np.abs(np.mean(x) - data_mu) / data_mu\n",
    "    var_err = np.abs(np.var(x) - data_var) / data_var\n",
    "    return mu_err + var_err\n",
    "\n",
    "particles, weights, results_dict = abcsmc(\n",
    "    nparticles=1000, \n",
    "    nparams=2, \n",
    "    prior_list=prior_list, \n",
    "    niters=5,\n",
    "    sim_func=f_sim,\n",
    "    dist_func=f_dist, \n",
    "    eps0=5, \n",
    "    eps_percentile=0.15, \n",
    "    min_eps=0, \n",
    "    kernel_method='locm'\n",
    ")\n",
    "\n",
    "particle_history = results_dict['particle_history']\n",
    "weight_history = results_dict['weight_history']\n",
    "score_history = results_dict['score_history']\n",
    "acceptance_rates = results_dict['acceptance_rates']\n",
    "epsilon_history = results_dict['epsilon_history']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(\n",
    "    particle_history, weight_history, score_history, acceptance_rates,\n",
    "    epsilon_history, prior_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_theta1 = 5\n",
    "true_theta2 = 0\n",
    "var_const = 0.5\n",
    "data = RingModel(true_theta1, true_theta2, var_const).generate_data(1)\n",
    "\n",
    "prior_theta1 = st.uniform(-10, 20)\n",
    "prior_theta2 = st.uniform(-10, 20)\n",
    "prior_list = [prior_theta1, prior_theta2]\n",
    "\n",
    "def f_sim(particle, n=1):\n",
    "    return RingModel(particle[0], particle[1], var_const).generate_data(n)\n",
    "\n",
    "def f_dist(x):\n",
    "    return np.linalg.norm(x - data)\n",
    "\n",
    "particles, weights, results_dict = abcsmc(\n",
    "    nparticles=500, \n",
    "    nparams=2, \n",
    "    prior_list=prior_list, \n",
    "    niters=5, \n",
    "    sim_func=f_sim,\n",
    "    dist_func=f_dist, \n",
    "    eps0=5, \n",
    "    eps_percentile=0.15, \n",
    "    min_eps=0, \n",
    "    kernel_method='locm',\n",
    ")\n",
    "\n",
    "particle_history = results_dict['particle_history']\n",
    "weight_history = results_dict['weight_history']\n",
    "score_history = results_dict['score_history']\n",
    "acceptance_rates = results_dict['acceptance_rates']\n",
    "epsilon_history = results_dict['epsilon_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(\n",
    "    particle_history, weight_history, score_history, acceptance_rates,\n",
    "    epsilon_history, prior_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
